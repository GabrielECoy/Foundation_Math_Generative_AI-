{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Machine Translation with CrossAttention\n",
        "\n",
        "Inspired highly on the tutorial [NMT with Attention](https://www.tensorflow.org/text/tutorials/nmt_with_attention) which takes the code from the original Seq2Seq with MHA attention [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025v5) (Luong et al., 2015)."
      ],
      "metadata": {
        "id": "gzf37X_XizQQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prep\n"
      ],
      "metadata": {
        "id": "aqEjUrqjzZJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installations and imports"
      ],
      "metadata": {
        "id": "e_nNUwag3OKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Everytime I run these notebooks I get the following warning:\n",
        "# \"The selected GPU type was not available. You are now connected to a T4\".\n",
        "# It seems that's something set in the notebook settings as it offers me to open it\n",
        "\n",
        "!pip install -U nltk 'tensorflow-text' 'keras-nlp' 'keras-preprocessing' # changed 'tensorflow-text==2.15.0' to just 'tensorflow-text' as version 2.15.0 is not available\n",
        "\n",
        "# added to fix the \"ModuleNotFoundError: No module named 'sklearn.model_szelection\" error in the next cell\n",
        "#!pip uninstall -y scikit-learn\n",
        "#!pip install scikit-learn\n",
        "#import sklearn\n",
        "# Finally realized the problem was the spelling of selection\n",
        "\n",
        "!pip install gensim # Because in Demo1 and 2 I use this to resolve the \"ModuleNotFoundError: No module named 'gensim'\" error"
      ],
      "metadata": {
        "id": "C9BTEOu0PerV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb712e7f-aa88-4e82-fc87-42729fc889ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.2)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: keras-nlp in /usr/local/lib/python3.12/dist-packages (0.22.2)\n",
            "Requirement already satisfied: keras-preprocessing in /usr/local/lib/python3.12/dist-packages (1.1.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: tensorflow<2.20,>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-text) (2.19.0)\n",
            "Requirement already satisfied: keras-hub==0.22.2 in /usr/local/lib/python3.12/dist-packages (from keras-nlp) (0.22.2)\n",
            "Requirement already satisfied: keras>=3.8 in /usr/local/lib/python3.12/dist-packages (from keras-hub==0.22.2->keras-nlp) (3.10.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras-hub==0.22.2->keras-nlp) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras-hub==0.22.2->keras-nlp) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras-hub==0.22.2->keras-nlp) (25.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras-hub==0.22.2->keras-nlp) (13.9.4)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (from keras-hub==0.22.2->keras-nlp) (0.3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from keras-preprocessing) (1.17.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (75.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (2.19.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (0.45.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.8->keras-hub==0.22.2->keras-nlp) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.8->keras-hub==0.22.2->keras-nlp) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (3.1.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub->keras-hub==0.22.2->keras-nlp) (6.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras-hub==0.22.2->keras-nlp) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras-hub==0.22.2->keras-nlp) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras-hub==0.22.2->keras-nlp) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (3.0.3)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Used this to check sklearn version, but I finally resolved by changes the import to tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import sklearn\n",
        "print (sklearn.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJFLwLC3RCM7",
        "outputId": "00d80ed3-cfd9-4fea-e6bc-5f7d98d666e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fpgYwAtNO2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7f7b77-895c-4801-b385-0324eadaa6c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import sys\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Lambda, ELU, Conv1D, MaxPooling1D, Dropout\n",
        "from keras.preprocessing import sequence\n",
        "# to fix the \"No module named 'keras.preprocessing.text'\" error I commented the following line and added the next one\n",
        "#from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import preprocessing\n",
        "from textblob import TextBlob, Word\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.initializers import Constant\n",
        "# I tried to remove the experimental part (as in Demo2), but it did not work, so I commented the line for now\n",
        "#from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras import Model, Input\n",
        "import tensorflow_text as tf_text\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "import gensim\n",
        "import warnings\n",
        "import nltk\n",
        "import time\n",
        "\n",
        "# Filter out warnings to keep the output clean during execution.\n",
        "warnings.filterwarnings('ignore')\n",
        "# Download the 'punkt' tokenizer from nltk, which is essential for tokenizing text into sentences or words.\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download and prepare the dataset\n",
        "\n",
        "The steps you need to take to prepare the data:\n",
        "\n",
        "1. Add a *start* and *end* token to each sentence.\n",
        "2. Clean the sentences by removing special characters.\n",
        "3. Create a word index and reverse word index (dictionaries mapping from word → id and id → word).\n",
        "4. Pad each sentence to a maximum length.\n"
      ],
      "metadata": {
        "id": "4_gfORYlopD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the %%writefile magic command to write the following lines to a file named get_data.sh.\n",
        "# The %%writefile magic command is a built-in command in Jupyter notebooks and Colab\n",
        "# that allows you to write the content of the cell to a specified file.\n",
        "%%writefile get_data.sh\n",
        "# Check if the file spa.txt does not exist\n",
        "if [ ! -f spa.txt ]; then\n",
        "  # If spa.txt does not exist, download it from the given URL and save it as spa.txt\n",
        "  wget -O spa.txt https://www.dropbox.com/s/ke42pnpydmy6oa6/spa.txt?dl=0\n",
        "fi"
      ],
      "metadata": {
        "id": "yFxoDROBpG5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49ee4257-7c26-4c6d-a774-4a3b5d963955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing get_data.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash get_data.sh"
      ],
      "metadata": {
        "id": "O2SKVt9TqEIw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c3a9a26-6960-4444-92f6-e8517aed6a97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-04 19:38:25--  https://www.dropbox.com/s/ke42pnpydmy6oa6/spa.txt?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.69.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.69.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.dropbox.com/scl/fi/5ovf4txnjfzcxt3ylskex/spa.txt?rlkey=t54t9t6txhoddwk0lfk6te9t5&dl=0 [following]\n",
            "--2025-10-04 19:38:26--  https://www.dropbox.com/scl/fi/5ovf4txnjfzcxt3ylskex/spa.txt?rlkey=t54t9t6txhoddwk0lfk6te9t5&dl=0\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc0cd1422130edd7acef106f7507.dl.dropboxusercontent.com/cd/0/inline/CykU2geqC_9rdxblq48t_psd4346YhQdZVQpPK4cg3fDMw_fvdNjox0-K0mSMR6WauFNUhhhS5QbyG1fRcTheSbmhuqDo1GL3vyAcYyOwlmyBWogx6FVb0gAWUzsFmGeDMwyMGz_P38569csSkgwn8MJ/file# [following]\n",
            "--2025-10-04 19:38:27--  https://uc0cd1422130edd7acef106f7507.dl.dropboxusercontent.com/cd/0/inline/CykU2geqC_9rdxblq48t_psd4346YhQdZVQpPK4cg3fDMw_fvdNjox0-K0mSMR6WauFNUhhhS5QbyG1fRcTheSbmhuqDo1GL3vyAcYyOwlmyBWogx6FVb0gAWUzsFmGeDMwyMGz_P38569csSkgwn8MJ/file\n",
            "Resolving uc0cd1422130edd7acef106f7507.dl.dropboxusercontent.com (uc0cd1422130edd7acef106f7507.dl.dropboxusercontent.com)... 162.125.69.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to uc0cd1422130edd7acef106f7507.dl.dropboxusercontent.com (uc0cd1422130edd7acef106f7507.dl.dropboxusercontent.com)|162.125.69.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8042772 (7.7M) [text/plain]\n",
            "Saving to: ‘spa.txt’\n",
            "\n",
            "spa.txt             100%[===================>]   7.67M  4.98MB/s    in 1.5s    \n",
            "\n",
            "2025-10-04 19:38:29 (4.98 MB/s) - ‘spa.txt’ saved [8042772/8042772]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! head spa.txt"
      ],
      "metadata": {
        "id": "5adiYIJJqFlK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a12726bc-275f-4346-acf1-880a28326f5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go.\tVe.\n",
            "Go.\tVete.\n",
            "Go.\tVaya.\n",
            "Go.\tVáyase.\n",
            "Hi.\tHola.\n",
            "Run!\t¡Corre!\n",
            "Run.\tCorred.\n",
            "Who?\t¿Quién?\n",
            "Fire!\t¡Fuego!\n",
            "Fire!\t¡Incendio!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "  # Read the text file from the given path with utf-8 encoding.\n",
        "  text = path.read_text(encoding='utf-8')\n",
        "\n",
        "  # Split the text into lines.\n",
        "  lines = text.splitlines()\n",
        "  # Split each line by the tab character to create pairs of source and target sentences.\n",
        "  pairs = [line.split('\\t') for line in lines]\n",
        "  # Example: If a line is \"Hello\\tHola\", pairs will contain [\"Hello\", \"Hola\"]\n",
        "  # If the input text was \"Go.\\tVe.\\nHi.\\tHola.\", the pairs variable would be [['Go.', 'Ve.'], ['Hi.', 'Hola.']]\n",
        "\n",
        "  # Extract the context sentences (second element of each pair) into a NumPy array.\n",
        "  # The `for target, context in pairs` loop iterates through each pair in the `pairs` list,\n",
        "  # assigning the first element to `target` and the second to `context` for each iteration.\n",
        "  # Example: Using the previous pairs example [['Go.', 'Ve.'], ['Hi.', 'Hola.']], context would be np.array(['Ve.', 'Hola.'])\n",
        "  context = np.array([context for target, context in pairs])\n",
        "  # Extract the target sentences (first element of each pair) into a NumPy array.\n",
        "  # Similar to the previous line, the loop iterates through the `pairs` list.\n",
        "  # Example: Using the previous pairs example [['Go.', 'Ve.'], ['Hi.', 'Hola.']], target would be np.array(['Go.', 'Hi.'])\n",
        "  target = np.array([target for target, context in pairs])\n",
        "\n",
        "  # Return the target and context arrays.\n",
        "  return target, context"
      ],
      "metadata": {
        "id": "NEvGjgBCqOqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "target_raw, context_raw = load_data(pathlib.Path('./spa.txt'))\n",
        "print(context_raw[-1])\n",
        "print(context_raw[0:5])"
      ],
      "metadata": {
        "id": "H6_Mg1wtqWiQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad1883eb-000d-4236-f16e-ec5f4104e070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.\n",
            "['Ve.' 'Vete.' 'Vaya.' 'Váyase.' 'Hola.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(target_raw[-1])\n",
        "print(target_raw[200:205])\n",
        "print(target_raw[-5:-1])"
      ],
      "metadata": {
        "id": "9W_00eXhqair",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d979e40e-82e9-492d-e088-239c1288ab10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\n",
            "['Back off.' 'Be a man.' 'Be brave.' 'Be brief.' 'Be brief.']\n",
            "['There are four main causes of alcohol-related death. Injury from car accidents or violence is one. Diseases like cirrhosis of the liver, cancer, heart and blood system diseases are the others.'\n",
            " \"There are mothers and fathers who will lie awake after the children fall asleep and wonder how they'll make the mortgage, or pay their doctor's bills, or save enough for their child's college education.\"\n",
            " 'A carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities. Some people try to reduce their carbon footprint because they are concerned about climate change.'\n",
            " 'Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the buffer size for shuffling the dataset to the total number of samples.\n",
        "BUFFER_SIZE = len(context_raw)\n",
        "# Set the batch size for training.\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Create a boolean array to randomly split the data into training (80%) and validation (20%) sets.\n",
        "# np.random.uniform generates random numbers between 0 and 1.\n",
        "# The comparison \"< 0.8\" is applied element-wise to the array generated by np.random.uniform.\n",
        "# This results in a boolean array where True indicates the element is included in the training set (approximately 80% of the data).\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "# Example: If len(target_raw) was 5, is_train could look like: [ True, False, True, True, False]\n",
        "\n",
        "# Create a TensorFlow Dataset for the training data.\n",
        "# .from_tensor_slices() creates a dataset from the slices of the given tensors.\n",
        "# When a boolean array like `is_train` is used to index a NumPy array (e.g., `context_raw[is_train]`),\n",
        "# it selects only the elements from `context_raw` where the corresponding value in `is_train` is True.\n",
        "# .shuffle(BUFFER_SIZE) shuffles the elements of the dataset with a buffer of size BUFFER_SIZE.\n",
        "# .batch(BATCH_SIZE) combines consecutive elements into batches of size BATCH_SIZE.\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "# Create a TensorFlow Dataset for the validation data.\n",
        "# ~is_train selects the elements that are not in the training set.\n",
        "# Similar to the training set, `context_raw[~is_train]` selects elements where `is_train` is False.\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ],
      "metadata": {
        "id": "FDwRq7K7q3md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "  print(example_context_strings[:5])\n",
        "  print()\n",
        "  print(example_target_strings[:5])\n",
        "  break"
      ],
      "metadata": {
        "id": "dXznSCd9uoDy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "976cdfa1-337e-4d7a-bde5-79363c95b55d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'Es tan agradable quedarse en casa.'\n",
            " b'De ninguna manera lo aceptar\\xc3\\xa9.' b'Fui a Boston en coche.'\n",
            " b'Tom le pidi\\xc3\\xb3 a Mary que le hiciera algo de comer.'\n",
            " b'Tom no se merece otra oportunidad.'], shape=(5,), dtype=string)\n",
            "\n",
            "tf.Tensor(\n",
            "[b\"It's so nice to stay at home.\" b'By no means will I accept it.'\n",
            " b'I went to Boston by car.'\n",
            " b'Tom asked Mary to make him something to eat.'\n",
            " b\"Tom doesn't deserve another chance.\"], shape=(5,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text processing"
      ],
      "metadata": {
        "id": "GMiMKp7zyCPb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ],
      "metadata": {
        "id": "kAW-e9tjyBUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = tf.constant('¿Todavía está en casa?')\n",
        "\n",
        "print(example_text.numpy())\n",
        "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ],
      "metadata": {
        "id": "NGMCXqX0uqVN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e9c29f-c546-46c7-fe23-f55206edf51b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'\\xc2\\xbfTodav\\xc3\\xada est\\xc3\\xa1 en casa?'\n",
            "b'\\xc2\\xbfTodavi\\xcc\\x81a esta\\xcc\\x81 en casa?'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text"
      ],
      "metadata": {
        "id": "ZJ3IrLGayGb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(example_text.numpy().decode())\n",
        "print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ],
      "metadata": {
        "id": "27J5Iii0yPwL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cf5b291-a0c6-4e3d-f771-66be826d1439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¿Todavía está en casa?\n",
            "[START] ¿ todavia esta en casa ? [END]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Vectorization\n"
      ],
      "metadata": {
        "id": "K_fqO7pRyrF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here comes the key part, using the layer TextVectorization we provide how to process text and how to construct the vocabulary, which we will later refer back"
      ],
      "metadata": {
        "id": "HGL6UpJp2XVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_vocab_size = 5000 # Define the maximum vocabulary size.\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct, # Specify the function to use for text standardization.\n",
        "    max_tokens=max_vocab_size, # Set the maximum number of tokens (vocabulary size).\n",
        "    ragged=True) # Output ragged tensors, which can have varying lengths."
      ],
      "metadata": {
        "id": "X6EERfaPyRo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Adapt the text processor to the training context data.\n",
        " # This step analyzes the data to build the vocabulary based on the unique tokens found.\n",
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "context_text_processor.get_vocabulary()[:10] # Get the first 10 words from the built vocabulary."
      ],
      "metadata": {
        "id": "E5pNEEkGyuQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deab663d-5b6e-416b-eaac-0d63dcd60217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', '.', 'que', 'de', 'el', 'a', 'no']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "target_text_processor.get_vocabulary()[:10]"
      ],
      "metadata": {
        "id": "4DOY9054yyct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a46780b-f0ff-4ec3-b5ee-366330313701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', '.', 'the', 'i', 'to', 'you', 'tom']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "notice we passed to ids, not padded yet"
      ],
      "metadata": {
        "id": "XoJUN_bm0-vW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the example context strings to tokens using the context text processor.\n",
        "# The result is a ragged tensor because the input strings have varying lengths after processing.\n",
        "example_tokens = context_text_processor(example_context_strings)\n",
        "# Display the first 3 rows of the example tokens, showing the token IDs for the first few context strings.\n",
        "example_tokens[:3, :]"
      ],
      "metadata": {
        "id": "HimOaXcQzGf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d154f1-2dec-476e-f910-399fb69b37f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 15, 65, 1122, 934, 14, 51, 4, 3], [2, 6, 502, 463, 22, 1, 4, 3],\n",
              " [2, 274, 8, 135, 14, 155, 4, 3]]>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the ragged tensor of example tokens to a dense tensor, padding with 0s where necessary.\n",
        "# A ragged tensor has sequences of varying lengths, while a dense tensor has sequences of the same length, padded with a value (usually 0).\n",
        "# This is required for plotting with pcolormesh, which expects a dense, rectangular grid of data.\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "print(example_tokens.to_tensor()[:3, :])\n",
        "# Set the title of the plot.\n",
        "plt.title('Token IDs')\n",
        "# Display the plot.\n",
        "plt.show() # Added show() to display the plot explicitly\n",
        "# The plot shows the token IDs as a pseudocolor plot. Each row represents a sentence, and the color intensity corresponds to the token ID.\n",
        "# Padding tokens (with ID 0) are typically shown in a distinct color or are absent."
      ],
      "metadata": {
        "id": "KylJg74M0z83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "fa1072dd-33b0-4424-865c-ba275a570c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[   2   15   65 1122  934   14   51    4    3    0    0    0    0    0\n",
            "     0    0]\n",
            " [   2    6  502  463   22    1    4    3    0    0    0    0    0    0\n",
            "     0    0]\n",
            " [   2  274    8  135   14  155    4    3    0    0    0    0    0    0\n",
            "     0    0]], shape=(3, 16), dtype=int64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process the dataset\n",
        "\n",
        "\n",
        "\n",
        "The process_text function below converts the Datasets of strings, into 0-padded tensors of token IDs. It also converts from a (context, target) pair to an ((context, target_in), target_out) pair for training with keras.Model.fit. Keras expects (inputs, labels) pairs, the inputs are the (context, target_in) and the labels are target_out. The difference between target_in and target_out is that they are shifted by one step relative to eachother, so that at each location the label is the next token.\n"
      ],
      "metadata": {
        "id": "xPBYT7ig1upS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process the text data\n",
        "def process_text(context, target):\n",
        "  # Convert context text to token IDs using the context text processor and convert to a dense tensor\n",
        "  # Context is converted to a dense tensor immediately because the encoder processes the entire sequence at once.\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  # Convert target text to token IDs using the target text processor (result is a ragged tensor)\n",
        "  # .to_tensor() is not used here because target_text_processor is configured to output ragged tensors (ragged=True).\n",
        "  # The slicing operations target[:,:-1] and target[:,1:] work directly on the ragged tensor before converting to dense tensors.\n",
        "  target = target_text_processor(target)\n",
        "  # Extract target input sequence (all tokens except the last one) and convert to a dense tensor\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  # Extract target output sequence (all tokens except the first one) and convert to a dense tensor\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  # Return the input pair ((context, targ_in)) and the output (targ_out) for training\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "# Apply the process_text function to the training raw dataset.\n",
        "# This transforms the raw training data (strings) into processed tensors (token IDs).\n",
        "# tf.data.AUTOTUNE allows TensorFlow to automatically tune the number of parallel calls for mapping.\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "# Apply the process_text function to the validation raw dataset.\n",
        "# This transforms the raw validation data (strings) into processed tensors (token IDs), similar to the training data.\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "pzfHsUTz1EeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the first element (batch) of the training dataset.\n",
        "# train_ds.take(1) gets a single batch from the dataset.\n",
        "# The batch is a tuple: ((context_tokens, target_input_tokens), target_output_tokens)\n",
        "# The for loop unpacks this tuple into the variables:\n",
        "# (ex_context_tok, ex_tar_in): This is the input to the model, a tuple containing context tokens and target input tokens.\n",
        "# ex_tar_out: This is the expected output (labels) for the model, containing target output tokens.\n",
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  # Print the first 10 token IDs of the first context sequence in the batch.\n",
        "  print(ex_context_tok[0, :10].numpy())\n",
        "  print() # Print a blank line for better readability.\n",
        "  # Print the first 10 token IDs of the first target input sequence in the batch.\n",
        "  print(ex_tar_in[0, :10].numpy())\n",
        "  # Print the first 10 token IDs of the first target output sequence (labels) in the batch.\n",
        "  print(ex_tar_out[0, :10].numpy())\n",
        "  break # Stop after processing the first batch."
      ],
      "metadata": {
        "id": "ZbTe79To1yXq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f006d5b-0916-4336-e646-0927beb9cec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  2  13  53   1   6 135  12   3   0   0]\n",
            "\n",
            "[  2  69  56   8  80 118  68 168  11   0]\n",
            "[ 69  56   8  80 118  68 168  11   3   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "<table><tr>  <td>   <img width=500 src=\"https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg\"/>  </td>  <td>   <img width=380 src=\"https://www.tensorflow.org/images/tutorials/transformer/RNN+attention.png\"/>  </td></tr><tr>  <th colspan=1>The original from <a href=https://arxiv.org/abs/1508.04025v5>Effective Approaches to Attention-based Neural Machine Translation</a></th>  <th colspan=1>This tutorial's model</th><tr></table>"
      ],
      "metadata": {
        "id": "uWfBbVGm5BXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UNITS = 256"
      ],
      "metadata": {
        "id": "ZE5vORUR19UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder"
      ],
      "metadata": {
        "id": "DVNCHzjQ7kNh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img width=500 src=\"https://tensorflow.org/images/tutorials/transformer/RNN-bidirectional.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>A bidirectional RNN</th>\n",
        "<tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "zeM4v2AB5Mtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super().__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "\n",
        "    # The embedding layer converts tokens to vectors\n",
        "    # It maps integer token IDs to dense vectors of fixed size (units).\n",
        "    # mask_zero=True: Specifies that the padding value (0) should be masked out,\n",
        "    # meaning the embedding layer will not produce an output for the padding token,\n",
        "    # and subsequent layers will ignore these masked values.\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    # Bidirectional wrapper: Makes the GRU layer process the input sequence in both forward and backward directions.\n",
        "    # merge_mode='sum': The outputs from the forward and backward GRU layers are summed.\n",
        "    # GRU (Gated Recurrent Unit): A type of recurrent neural network layer that processes sequences and maintains an internal state.\n",
        "    # units: The number of units in the GRU layer, which determines the dimensionality of the output space.\n",
        "    # return_sequences=True: The GRU layer returns the hidden state output for each time step in the input sequence.\n",
        "    # recurrent_initializer='glorot_uniform': Initializes the recurrent weights using the Glorot uniform initializer,\n",
        "    # which helps in preventing vanishing/exploding gradients during training.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    # The call method defines the forward pass of the encoder layer.\n",
        "    # x: Input tensor (token IDs).\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    # The bidirectional GRU processes the embedded sequence and returns a new sequence of combined outputs.\n",
        "    x = self.rnn(x)\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings (encoder output).\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    # This function is used to process raw text inputs for translation.\n",
        "    # texts: A tensor of raw text strings.\n",
        "\n",
        "    # Convert the input texts to a TensorFlow tensor.\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    # If the input is a single string (scalar tensor), add a batch dimension.\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    # Process the texts using the text processor to get token IDs and convert to a dense tensor.\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    # Pass the token IDs through the encoder layer (calls the self.call method).\n",
        "    context = self(context)\n",
        "    # Return the encoded context.\n",
        "    return context"
      ],
      "metadata": {
        "id": "fFO-NPNh5NCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ],
      "metadata": {
        "id": "qXHXm1cC7O9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bb90fad-1a76-4a4d-aa60-d60eeff3ffbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (64, 24)\n",
            "Encoder output, shape (batch, s, units): (64, 24, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Attention\n",
        "\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img width=500 src=\"https://www.tensorflow.org/images/tutorials/transformer/CrossAttention-new-full.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th colspan=1>The attention layer</th>\n",
        "<tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "sToo6RRl7man"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    # MultiHeadAttention layer for computing attention weights.\n",
        "    # key_dim: The dimensionality of the key vectors.\n",
        "    # num_heads: The number of attention heads.\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    # LayerNormalization layer for normalizing the output.\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    # Add layer for residual connection.\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    # Compute multi-head attention.\n",
        "    # query: The query tensor (e.g., decoder output).\n",
        "    # value: The value tensor (e.g., encoder output).\n",
        "    # return_attention_scores: If True, also returns the attention scores.\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        value=context,\n",
        "        return_attention_scores=True)\n",
        "\n",
        "    # Cache the attention scores for plotting later.\n",
        "    # Reduce the mean across the attention heads (axis=1).\n",
        "    # tf.reduce_mean calculates the mean of elements across the specified axis of a tensor.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    # Apply residual connection and layer normalization.\n",
        "    x = self.add([x, attn_output])  # Residual Connection: Adds the input x to the attention output.\n",
        "    x = self.layernorm(x) # Normalize the combined output.\n",
        "\n",
        "    # Return the output after attention, residual connection, and normalization.\n",
        "    return x"
      ],
      "metadata": {
        "id": "HKmRTPRF7RSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the CrossAttention layer with the specified number of units.\n",
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "# Create an Embedding layer for the target text.\n",
        "# target_text_processor.vocabulary_size(): Gets the size of the target vocabulary.\n",
        "# output_dim=UNITS: Sets the dimensionality of the embedding vectors to the same number of units as the encoder and attention layer.\n",
        "# mask_zero=True: Specifies that the padding value (0) should be masked out.\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                  output_dim=UNITS, mask_zero=True)\n",
        "# Embed the example target input tokens.\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "# Apply the attention layer to the embedded target tokens and the encoder output (context).\n",
        "# The attention layer calculates attention weights and produces an output that is a weighted sum of the context based on the target.\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "# Print the shapes of the input and output tensors to understand the dimensions.\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')\n",
        "\n",
        "# Outputs Explanation:\n",
        "# Context sequence shape: (batch_size, source_sequence_length, units) - The output of the encoder.\n",
        "# Target sequence shape: (batch_size, target_sequence_length, units) - The embedded target input tokens.\n",
        "# Attention result shape: (batch_size, target_sequence_length, units) - The output of the attention layer, same shape as the target sequence.\n",
        "# Attention weights shape: (batch_size, target_sequence_length, source_sequence_length) - The attention weights, indicating how much each target token attends to each source token."
      ],
      "metadata": {
        "id": "JkYeDMAu-gYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c0b0144-6a51-492b-c65a-6f63dd7789a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (64, 24, 256)\n",
            "Target sequence, shape (batch, t, units): (64, 22, 256)\n",
            "Attention result, shape (batch, t, units): (64, 22, 256)\n",
            "Attention weights, shape (batch, t, s):    (64, 22, 24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the sum of attention weights across the source sequence (axis=-1) for the first example in the batch (index 0).\n",
        "# The sum should be approximately 1 for each target token, indicating that the attention weights are normalized across the source sequence.\n",
        "# The output is an array where each value corresponds to a target token and represents the sum of its attention weights over all source tokens.\n",
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ],
      "metadata": {
        "id": "U4fpqeiS-mk2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31a7c0d0-2da2-4376-a61f-5a133db07c09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 1.0000001 , 0.99999994, 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n",
        "\n",
        "When training, the model predicts the next word at each location. So it's important that the information only flows in one direction through the model. The decoder uses a unidirectional (not bidirectional) RNN to process the target sequence.\n",
        "\n",
        "When running inference with this model it produces one word at a time, and those are fed back into the model.\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img width=500 src=\"https://tensorflow.org/images/tutorials/transformer/RNN.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>A unidirectional RNN</th>\n",
        "<tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "ltzIJ4uI_ERJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super().__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                                units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                    return_sequences=True,\n",
        "                                    return_state=True,\n",
        "                                    recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)\n",
        "\n",
        "  def call(self, context, x, state=None, return_state=False):\n",
        "\n",
        "    # 1. Lookup the embeddings\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # 2. Process the target sequence.\n",
        "    # Handle initial state correctly when it's None\n",
        "    # if else statement added by Gemini, because I got the following error in the next-next cell:\n",
        "    # \"Exception encountered when calling Decoder.call(). too many values to unpack (expected 2\"\n",
        "    # Gemini said:\n",
        "    # \"The error ValueError: too many values to unpack (expected 2) in cell _TJ-zsUczJyW occurs in the Decoder's call method when\n",
        "    # calling the GRU layer. This is because the GRU layer is configured to return both the sequence of outputs and the final state\n",
        "    # (return_sequences=True, return_state=True). The code attempts to unpack these two outputs into x and state. The issue arises\n",
        "    # when initial_state is None in the first call, which causes the GRU's behavior to differ slightly in how it returns the state.\n",
        "    # To fix this, I will modify the Decoder's call method in cell pCyAFrEN-_RV to handle the initial state correctly when it's None.\n",
        "    # I will check if state is None and pass initial_state=None to the GRU call accordingly.\"\n",
        "\n",
        "    # I still kept getting the error, so I'll just follow the video\n",
        "    if state is None:\n",
        "      x, state = self.rnn(x)\n",
        "    else:\n",
        "      x, state = self.rnn(x, initial_state=state)\n",
        "\n",
        "    # 3. Use the RNN output as the query for the attention over the context.\n",
        "    x = self.attention(x, context)\n",
        "    self.last_attention_weights = self.attention.last_attention_weights\n",
        "\n",
        "    # Step 4. Generate logit predictions for the next token.\n",
        "    logits = self.output_layer(x)\n",
        "\n",
        "    if return_state:\n",
        "      return logits, state\n",
        "    else:\n",
        "      return logits\n",
        "\n",
        "# Stuff we will need for inference\n",
        "\n",
        "  def get_initial_state(self, context):\n",
        "    batch_size = tf.shape(context)[0]\n",
        "    start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "    done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "    embedded = self.embedding(start_tokens)\n",
        "    # GRU layer's get_initial_state returns a tuple of states\n",
        "    return start_tokens, done, self.rnn.get_initial_state(embedded)[0]\n",
        "\n",
        "  def tokens_to_text(self, tokens):\n",
        "    words = self.id_to_word(tokens)\n",
        "    result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "    result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "    result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "    return result\n",
        "\n",
        "  def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "    logits, state = self(context, next_token, state = state, return_state=True)\n",
        "\n",
        "    if temperature == 0.0:\n",
        "      next_token = tf.argmax(logits, axis=-1)\n",
        "    else:\n",
        "      logits = logits[:, -1, :]/temperature\n",
        "      next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "    # If a sequence produces an `end_token`, set it `done`\n",
        "    done = done | (next_token == self.end_token)\n",
        "    # Once a sequence is done it only produces 0-padding.\n",
        "    next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "\n",
        "    return next_token, done, state"
      ],
      "metadata": {
        "id": "pCyAFrEN-_RV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ],
      "metadata": {
        "id": "NxZeL4tbzDPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ],
      "metadata": {
        "id": "_TJ-zsUczJyW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "outputId": "3183b31d-b5f4-4a39-c8c8-121501a61693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling Decoder.call().\n\n\u001b[1mtoo many values to unpack (expected 2)\u001b[0m\n\nArguments received by Decoder.call():\n  • context=tf.Tensor(shape=(64, 24, 256), dtype=float32)\n  • x=tf.Tensor(shape=(64, 22), dtype=int64)\n  • state=None\n  • return_state=False",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-347216325.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex_tar_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'encoder output shape: (batch, s, units) {ex_context.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'input target tokens shape: (batch, t) {ex_tar_in.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'logits shape shape: (batch, t, target_vocabulary_size) {logits.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3828040702.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, context, x, state, return_state)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# I will check if state is None and pass initial_state=None to the GRU call accordingly.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Decoder.call().\n\n\u001b[1mtoo many values to unpack (expected 2)\u001b[0m\n\nArguments received by Decoder.call():\n  • context=tf.Tensor(shape=(64, 24, 256), dtype=float32)\n  • x=tf.Tensor(shape=(64, 22), dtype=int64)\n  • state=None\n  • return_state=False"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The model"
      ],
      "metadata": {
        "id": "Ec4E2iEuzZbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Translator(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, units, context_text_processor, target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "    return logits\n",
        "\n",
        "  def translate(self, texts, *, max_length=50, temperature=0.0):\n",
        "    # Process the input texts\n",
        "    context = self.encoder.convert_input(texts)\n",
        "    batch_size = tf.shape(texts)[0]\n",
        "\n",
        "    # Setup the loop inputs\n",
        "    tokens = []\n",
        "    attention_weights = []\n",
        "    next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "    for _ in range(max_length):\n",
        "      # Generate the next token\n",
        "      next_token, done, state = self.decoder.get_next_token(\n",
        "          context, next_token, done,  state, temperature)\n",
        "\n",
        "      # Collect the generated tokens\n",
        "      tokens.append(next_token)\n",
        "      attention_weights.append(self.decoder.last_attention_weights)\n",
        "\n",
        "      if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "        break\n",
        "\n",
        "    # Stack the lists of tokens and attention weights.\n",
        "    tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "    self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "    result = self.decoder.tokens_to_text(tokens)\n",
        "    return result"
      ],
      "metadata": {
        "id": "o9gAwRnfzS5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)"
      ],
      "metadata": {
        "id": "L4pwcmG4zm7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ],
      "metadata": {
        "id": "LD-Stro8zt3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Hftseyhtzuub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "h8gLXK36CL2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "EQpVGnsFz1UL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "\n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "\n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "QR4M7-6jCPOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=masked_loss,\n",
        "              metrics=[masked_acc, masked_loss])"
      ],
      "metadata": {
        "id": "L46lhkXcCRVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(),\n",
        "    epochs=25,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 20,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=3)])"
      ],
      "metadata": {
        "id": "Y0whEYLfCTXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "p-6tYeLrCWfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0PElshfcCcHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "ODcFQZlNCcrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translate"
      ],
      "metadata": {
        "id": "ARqmE2hkC4Y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.translate(['¿Todavía está en casa?']) # Are you still home\n",
        "result[0].numpy().decode()"
      ],
      "metadata": {
        "id": "EvHhW0WBC4Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_attention(model, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = model.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = model.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ],
      "metadata": {
        "id": "-NiUPbcJDClm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_attention(model, '¿Todavía está en casa?')"
      ],
      "metadata": {
        "id": "jgLjApd6DNTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_attention(model, 'Esta es mi vida.')"
      ],
      "metadata": {
        "id": "P9TDUQARDR2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ],
      "metadata": {
        "id": "qGwFh31nDZS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.translate([long_text])\n",
        "result[0].numpy().decode()"
      ],
      "metadata": {
        "id": "HdzOZYMmdcJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_attention(model, long_text)"
      ],
      "metadata": {
        "id": "rdF5n6HIDZ6V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}